{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install requests pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWGF5qLAsR0S",
        "outputId": "f5609b1c-babc-4423-846d-4834b736cd45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "import logging\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "class GitHubScraper:\n",
        "    def __init__(self, token: str):\n",
        "        \"\"\"\n",
        "        Initialize the GitHub scraper with your API token.\n",
        "\n",
        "        Args:\n",
        "            token (str): GitHub Personal Access Token\n",
        "        \"\"\"\n",
        "        self.headers = {\n",
        "            'Authorization': f'token {token}',\n",
        "            'Accept': 'application/vnd.github.v3+json'\n",
        "        }\n",
        "        self.base_url = 'https://api.github.com'\n",
        "\n",
        "        # Setup logging\n",
        "        logging.basicConfig(\n",
        "            level=logging.INFO,\n",
        "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
        "        )\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "    def _make_request(self, url: str, params: dict = None) -> Dict:\n",
        "        \"\"\"\n",
        "        Make a request to the GitHub API with rate limit handling.\n",
        "        \"\"\"\n",
        "        while True:\n",
        "            response = requests.get(url, headers=self.headers, params=params)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                return response.json()\n",
        "            elif response.status_code == 403:\n",
        "                reset_time = int(response.headers.get('X-RateLimit-Reset', 0))\n",
        "                sleep_time = max(reset_time - time.time(), 0) + 1\n",
        "                self.logger.warning(f\"Rate limit hit. Sleeping for {sleep_time} seconds\")\n",
        "                time.sleep(sleep_time)\n",
        "            else:\n",
        "                self.logger.error(f\"Error {response.status_code}: {response.text}\")\n",
        "                response.raise_for_status()\n",
        "\n",
        "    def clean_company_name(self, company: str) -> str:\n",
        "        \"\"\"\n",
        "        Clean up company names according to specifications.\n",
        "        \"\"\"\n",
        "        if not company:\n",
        "            return \"\"\n",
        "\n",
        "        # Strip whitespace and @ symbol\n",
        "        cleaned = company.strip().lstrip('@')\n",
        "\n",
        "        # Convert to uppercase\n",
        "        return cleaned.upper()\n",
        "\n",
        "    def search_users(self, location: str, min_followers: int) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Search for GitHub users in a specific location with minimum followers.\n",
        "        \"\"\"\n",
        "        users = []\n",
        "        page = 1\n",
        "\n",
        "        while True:\n",
        "            self.logger.info(f\"Fetching users page {page}\")\n",
        "\n",
        "            query = f\"location:{location} followers:>={min_followers}\"\n",
        "            params = {\n",
        "                'q': query,\n",
        "                'per_page': 100,\n",
        "                'page': page\n",
        "            }\n",
        "\n",
        "            url = f\"{self.base_url}/search/users\"\n",
        "            response = self._make_request(url, params)\n",
        "\n",
        "            if not response['items']:\n",
        "                break\n",
        "\n",
        "            for user in response['items']:\n",
        "                user_data = self._make_request(user['url'])\n",
        "\n",
        "                # Extract only the required fields with exact matching names\n",
        "                cleaned_data = {\n",
        "                    'login': user_data['login'],\n",
        "                    'name': user_data['name'] if user_data['name'] else \"\",\n",
        "                    'company': self.clean_company_name(user_data.get('company')),\n",
        "                    'location': user_data['location'] if user_data['location'] else \"\",\n",
        "                    'email': user_data['email'] if user_data['email'] else \"\",\n",
        "                    'hireable': user_data['hireable'] if user_data['hireable'] is not None else False,\n",
        "                    'bio': user_data['bio'] if user_data['bio'] else \"\",\n",
        "                    'public_repos': user_data['public_repos'],\n",
        "                    'followers': user_data['followers'],\n",
        "                    'following': user_data['following'],\n",
        "                    'created_at': user_data['created_at']\n",
        "                }\n",
        "\n",
        "                users.append(cleaned_data)\n",
        "\n",
        "            page += 1\n",
        "\n",
        "        return users\n",
        "\n",
        "    def get_user_repositories(self, username: str, max_repos: int = 500) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Get repositories for a specific user.\n",
        "        \"\"\"\n",
        "        repos = []\n",
        "        page = 1\n",
        "\n",
        "        while len(repos) < max_repos:\n",
        "            self.logger.info(f\"Fetching repositories for {username}, page {page}\")\n",
        "\n",
        "            params = {\n",
        "                'sort': 'pushed',\n",
        "                'direction': 'desc',\n",
        "                'per_page': 100,\n",
        "                'page': page\n",
        "            }\n",
        "\n",
        "            url = f\"{self.base_url}/users/{username}/repos\"\n",
        "            response = self._make_request(url, params)\n",
        "\n",
        "            if not response:\n",
        "                break\n",
        "\n",
        "            for repo in response:\n",
        "                # Extract only the required fields with exact matching names\n",
        "                repo_data = {\n",
        "                    'login': username,  # Adding owner's login as required\n",
        "                    'full_name': repo['full_name'],\n",
        "                    'created_at': repo['created_at'],\n",
        "                    'stargazers_count': repo['stargazers_count'],\n",
        "                    'watchers_count': repo['watchers_count'],\n",
        "                    'language': repo['language'] if repo['language'] else \"\",\n",
        "                    'has_projects': repo['has_projects'],\n",
        "                    'has_wiki': repo['has_wiki'],\n",
        "                    'license_name': repo['license']['key'] if repo.get('license') else \"\"\n",
        "                }\n",
        "\n",
        "                repos.append(repo_data)\n",
        "\n",
        "            if len(response) < 100:\n",
        "                break\n",
        "\n",
        "            page += 1\n",
        "\n",
        "        return repos[:max_repos]\n",
        "\n",
        "def main():\n",
        "    # Get GitHub token\n",
        "    token = input(\"Enter your GitHub token: \").strip()\n",
        "    if not token:\n",
        "        print(\"Token is required. Exiting...\")\n",
        "        return\n",
        "\n",
        "    # Initialize scraper\n",
        "    scraper = GitHubScraper(token)\n",
        "\n",
        "    # Search for users in Sydney with >100 followers\n",
        "    users = scraper.search_users(location='Sydney', min_followers=100)\n",
        "\n",
        "    # Save users to CSV\n",
        "    users_df = pd.DataFrame(users)\n",
        "    users_df.to_csv('users.csv', index=False)\n",
        "\n",
        "    # Get repositories for each user\n",
        "    all_repos = []\n",
        "    for user in users:\n",
        "        repos = scraper.get_user_repositories(user['login'])\n",
        "        all_repos.extend(repos)\n",
        "\n",
        "    # Save repositories to CSV\n",
        "    repos_df = pd.DataFrame(all_repos)\n",
        "    repos_df.to_csv('repositories.csv', index=False)\n",
        "\n",
        "    print(f\"Scraped {len(users)} users and {len(all_repos)} repositories\")\n",
        "\n",
        "    # Create README.md\n",
        "    with open('README.md', 'w') as f:\n",
        "        f.write(f\"\"\"# GitHub Users in Sydney\n",
        "\n",
        "This repository contains data about GitHub users in Sydney with over 100 followers and their repositories.\n",
        "\n",
        "## Files\n",
        "\n",
        "1. `users.csv`: Contains information about {len(users)} GitHub users in Sydney with over 100 followers\n",
        "2. `repositories.csv`: Contains information about {len(all_repos)} public repositories from these users\n",
        "3. `gitscrap.py`: Python script used to collect this data\n",
        "\n",
        "## Data Collection\n",
        "\n",
        "- Data collected using GitHub API\n",
        "- Date of collection: {time.strftime('%Y-%m-%d')}\n",
        "- Only included users with 100+ followers\n",
        "- Up to 500 most recently pushed repositories per user\n",
        "\"\"\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtec3i7IsU-M",
        "outputId": "c1dd685c-605a-4bc7-c501-773453efb283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraped 375 users and 32758 repositories\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('users.csv')\n",
        "files.download('repositories.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "hTHi6afavhgd",
        "outputId": "217f2647-b6a0-4659-b424-dd88c3d12306"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b6f096c4-212d-41bb-9af9-617656d1eb2b\", \"users.csv\", 53688)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9e7ff949-14a2-4efb-aba4-eae78ec7fc47\", \"repositories.csv\", 2651296)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users data\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Filter for users located in Sydney\n",
        "sydney_users = users_df[users_df['location'].str.contains('Sydney', case=False, na=False)]\n",
        "\n",
        "# Sort users by followers count in descending order\n",
        "top_sydney_users = sydney_users.sort_values(by='followers', ascending=False).head(5)\n",
        "\n",
        "# Extract the login names\n",
        "top_logins = top_sydney_users['login'].tolist()\n",
        "\n",
        "# Create a comma-separated string\n",
        "top_logins_string = ', '.join(top_logins)\n",
        "\n",
        "print(\"Top 5 users in Sydney with the highest number of followers:\")\n",
        "print(top_logins_string)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMck4Aq0wvcB",
        "outputId": "4be4497f-19f5-4d02-d9dc-712ba55ab60f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 users in Sydney with the highest number of followers:\n",
            "nicknochnack, brendangregg, cornflourblue, 0vm, davecheney\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users data\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Convert the 'created_at' column to datetime\n",
        "users_df['created_at'] = pd.to_datetime(users_df['created_at'])\n",
        "\n",
        "# Filter for users located in Sydney\n",
        "sydney_users = users_df[users_df['location'].str.contains('Sydney', case=False, na=False)]\n",
        "\n",
        "# Sort users by 'created_at' in ascending order\n",
        "earliest_sydney_users = sydney_users.sort_values(by='created_at').head(5)\n",
        "\n",
        "# Extract the login names\n",
        "earliest_logins = earliest_sydney_users['login'].tolist()\n",
        "\n",
        "# Create a comma-separated string\n",
        "earliest_logins_string = ', '.join(earliest_logins)\n",
        "\n",
        "print(\"Top 5 earliest registered users in Sydney:\")\n",
        "print(earliest_logins_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irIK68bxxAvi",
        "outputId": "332f4f02-07a7-4b16-895e-4409cee692f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 earliest registered users in Sydney:\n",
            "dylanegan, cjheath, freshtonic, dhowden, mikel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Define the list to store users from Sydney\n",
        "users_in_sydney = []\n",
        "\n",
        "# Read the CSV file with UTF-8 encoding\n",
        "with open('users.csv', 'r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    for row in reader:\n",
        "        location = row['location'].strip().lower()\n",
        "        # Check if the user is from Sydney\n",
        "        if 'sydney' in location:\n",
        "            users_in_sydney.append({\n",
        "                'login': row['login'],\n",
        "                'followers': int(row['followers'])\n",
        "            })\n",
        "\n",
        "# Sort users based on followers in descending order\n",
        "top_users = sorted(users_in_sydney, key=lambda x: x['followers'], reverse=True)\n",
        "\n",
        "# Extract the top 5 user logins\n",
        "top_5_logins = [user['login'] for user in top_users[:5]]\n",
        "\n",
        "# Print the result as a comma-separated list\n",
        "print(', '.join(top_5_logins))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uiomrf-OxQRQ",
        "outputId": "4b8cfe84-d862-4bde-f04f-86c152618d84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nicknochnack, brendangregg, cornflourblue, 0vm, davecheney\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from collections import Counter\n",
        "\n",
        "# Define a Counter to count license occurrences\n",
        "license_counter = Counter()\n",
        "\n",
        "# Read the CSV file with UTF-8 encoding\n",
        "with open('users.csv', 'r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    for row in reader:\n",
        "        license_name = row['license_name'].strip()\n",
        "        # Ignore missing licenses\n",
        "        if license_name:\n",
        "            license_counter[license_name] += 1\n",
        "\n",
        "# Get the 3 most common licenses\n",
        "top_3_licenses = license_counter.most_common(3)\n",
        "\n",
        "# Extract license names and format them as a comma-separated string\n",
        "top_3_license_names = [license[0] for license in top_3_licenses]\n",
        "\n",
        "# Print the result\n",
        "print(', '.join(top_3_license_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "g_FuQyyRxaTY",
        "outputId": "dd7d32e9-3b92-4d1c-b889-8cb3ad6ef3b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'license_name'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-f229a70af720>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mlicense_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'license_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Ignore missing licenses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlicense_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'license_name'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sydney_users = users_df[users_df['location'].str.contains('Sydney', case=False, na=False)]\n",
        "top_5_sydney_users = sydney_users.sort_values(by='followers', ascending=False).head(5)\n",
        "\n",
        "# Extract the 'login' column as a comma-separated string\n",
        "top_5_logins = ', '.join(top_5_sydney_users['login'])\n",
        "top_5_logins"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "7UraMQgSypEZ",
        "outputId": "5dc0196a-3a89-4ca0-eafb-53b43cfc001b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'nicknochnack, brendangregg, cornflourblue, 0vm, davecheney'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from collections import Counter\n",
        "\n",
        "# Step 1: Create a mapping of user logins to their locations\n",
        "user_locations = {}\n",
        "with open('users.csv', 'r', encoding='utf-8') as user_file:\n",
        "    user_reader = csv.DictReader(user_file)\n",
        "    for row in user_reader:\n",
        "        user_locations[row['login']] = row['location'].strip().lower()\n",
        "\n",
        "# Step 2: Define a list to store programming languages for Sydney users\n",
        "languages_sydney = []\n",
        "\n",
        "# Step 3: Read the repositories CSV file and filter for Sydney users\n",
        "with open('repositories.csv', 'r', encoding='utf-8') as repo_file:\n",
        "    repo_reader = csv.DictReader(repo_file)\n",
        "    for row in repo_reader:\n",
        "        user_login = row['login']\n",
        "        language = row.get('language', '').strip()\n",
        "\n",
        "        # Check if the user is from Sydney and ignore empty languages\n",
        "        if user_login in user_locations and 'sydney' in user_locations[user_login]:\n",
        "            if language:\n",
        "                languages_sydney.append(language)\n",
        "\n",
        "# Step 4: Count the occurrence of each language\n",
        "language_counts = Counter(languages_sydney)\n",
        "\n",
        "# Step 5: Find the most common language\n",
        "most_common_language = language_counts.most_common(1)\n",
        "\n",
        "# Step 6: Print the result\n",
        "if most_common_language:\n",
        "    print(most_common_language[0][0])\n",
        "else:\n",
        "    print(\"No language data found for users in Sydney.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Us_TCu7zhWN",
        "outputId": "c7c98d40-06ba-4dd7-ad1e-d767232caf9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JavaScript\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from collections import defaultdict\n",
        "from datetime import datetime\n",
        "\n",
        "# Step 1: Create a dictionary to count repositories per user\n",
        "repository_counts = defaultdict(int)\n",
        "\n",
        "# Step 2: Read the repositories CSV file\n",
        "with open('repositories.csv', 'r', encoding='utf-8') as repo_file:\n",
        "    repo_reader = csv.DictReader(repo_file)\n",
        "    for row in repo_reader:\n",
        "        created_at = row['created_at']\n",
        "        user_login = row['login']\n",
        "\n",
        "        # Step 3: Convert created_at to a datetime object\n",
        "        created_date = datetime.fromisoformat(created_at[:-1])  # Remove the 'Z' and convert\n",
        "\n",
        "        # Step 4: Check if the day is Saturday (5) or Sunday (6)\n",
        "        if created_date.weekday() in [5, 6]:  # 5 for Saturday, 6 for Sunday\n",
        "            repository_counts[user_login] += 1\n",
        "\n",
        "# Step 5: Sort the users by the number of repositories created (descending)\n",
        "top_users = sorted(repository_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Step 6: Extract the top 5 user logins\n",
        "top_5_logins = [user[0] for user in top_users[:5]]\n",
        "\n",
        "# Step 7: Print the result as a comma-separated list\n",
        "print(','.join(top_5_logins))\n",
        "print(','.join(top_5_logins).strip())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zwbR-Km1eWk",
        "outputId": "c7334e74-31a7-4d23-cfa0-4c17d2dadc5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "timgates42,pinkforest,johndpope,mvandermeulen,mikeyhodl\n",
            "timgates42,pinkforest,johndpope,mvandermeulen,mikeyhodl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Define the list to store users from Sydney\n",
        "users_in_sydney = []\n",
        "\n",
        "# Read the CSV file with UTF-8 encoding\n",
        "with open('users.csv', 'r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    for row in reader:\n",
        "        location = row['location'].strip().lower()\n",
        "        # Check if the user is from Sydney\n",
        "        if 'sydney' in location:\n",
        "            users_in_sydney.append({\n",
        "                'login': row['login'],\n",
        "                'followers': int(row['followers'])\n",
        "            })\n",
        "\n",
        "# Sort users based on followers in descending order\n",
        "top_users = sorted(users_in_sydney, key=lambda x: x['followers'], reverse=True)\n",
        "\n",
        "# Extract the top 5 user logins\n",
        "top_5_logins = [user['login'] for user in top_users[:5]]\n",
        "\n",
        "# Print the result as a comma-separated list\n",
        "print(','.join(top_5_logins))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ8OM8FV7ghV",
        "outputId": "d95a8e75-4bab-4c13-86fd-04d91ea26c65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nicknochnack,brendangregg,cornflourblue,0vm,davecheney\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Define the list to store users from Sydney\n",
        "users_in_sydney = []\n",
        "\n",
        "# Read the CSV file with UTF-8 encoding\n",
        "with open('users.csv', 'r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    for row in reader:\n",
        "        location = row['location'].strip().lower()\n",
        "        # Check if the user is from Sydney\n",
        "        if 'sydney' in location:\n",
        "            users_in_sydney.append({\n",
        "                'login': row['login'],\n",
        "                'created_at': row['created_at']\n",
        "            })\n",
        "\n",
        "# Sort users based on created_at in ascending order\n",
        "earliest_users = sorted(users_in_sydney, key=lambda x: x['created_at'])\n",
        "\n",
        "# Extract the top 5 user logins\n",
        "top_5_earliest_logins = [user['login'] for user in earliest_users[:5]]\n",
        "\n",
        "# Print the result as a comma-separated list\n",
        "print(','.join(top_5_earliest_logins))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dIR58Nt7wDE",
        "outputId": "33124864-e1d3-4176-99d2-89243cc8aa98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dylanegan,cjheath,freshtonic,dhowden,mikel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from collections import Counter\n",
        "\n",
        "# Define the list to store licenses\n",
        "licenses = []\n",
        "\n",
        "# Read the CSV file with UTF-8 encoding\n",
        "with open('repositories.csv', 'r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    for row in reader:\n",
        "        # Get the license name (ignore empty values)\n",
        "        license_name = row.get('license_name', '').strip()\n",
        "        if license_name:  # Only consider non-empty license names\n",
        "            licenses.append(license_name)\n",
        "\n",
        "# Count the occurrence of each license\n",
        "license_counts = Counter(licenses)\n",
        "\n",
        "# Get the 3 most common licenses\n",
        "most_common_licenses = license_counts.most_common(3)\n",
        "\n",
        "# Extract the license names\n",
        "top_3_licenses = [license[0] for license in most_common_licenses]\n",
        "\n",
        "# Print the result as a comma-separated list\n",
        "print(','.join(top_3_licenses))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzL6X9Yf77pI",
        "outputId": "c49bbd93-a6ee-4549-dcf9-5e7dca424426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mit,other,apache-2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from collections import Counter\n",
        "\n",
        "# Define the list to store companies\n",
        "companies = []\n",
        "\n",
        "# Read the CSV file with UTF-8 encoding\n",
        "with open('users.csv', 'r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    for row in reader:\n",
        "        # Get the company name (ignore empty values)\n",
        "        company_name = row.get('company', '').strip()\n",
        "        if company_name:  # Only consider non-empty company names\n",
        "            companies.append(company_name)\n",
        "\n",
        "# Count the occurrence of each company\n",
        "company_counts = Counter(companies)\n",
        "\n",
        "# Find the most common company\n",
        "most_common_company = company_counts.most_common(1)\n",
        "\n",
        "# Print the result\n",
        "if most_common_company:\n",
        "    print(most_common_company[0][0])  # Company name\n",
        "else:\n",
        "    print(\"No company data found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZioLK6T8H76",
        "outputId": "d1c46cf8-6120-4fe6-ecb8-c8b7024059ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ATLASSIAN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from collections import Counter\n",
        "\n",
        "# Define the list to store programming languages\n",
        "languages = []\n",
        "\n",
        "# Read the CSV file with UTF-8 encoding\n",
        "with open('repositories.csv', 'r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    for row in reader:\n",
        "        # Get and clean up the language field (ignore empty values)\n",
        "        language = row.get('language', '').strip()\n",
        "        if language:  # Only consider non-empty language names\n",
        "            languages.append(language)\n",
        "\n",
        "# Count the occurrence of each language\n",
        "language_counts = Counter(languages)\n",
        "\n",
        "# Find the most common language\n",
        "most_common_language = language_counts.most_common(1)\n",
        "\n",
        "# Print the result\n",
        "if most_common_language:\n",
        "    print(most_common_language[0][0])  # Most popular programming language\n",
        "else:\n",
        "    print(\"No language data found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21zVCZdl8S0x",
        "outputId": "d82e71f5-a3b4-4b55-bad2-df0ae36304a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JavaScript\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from collections import Counter\n",
        "from datetime import datetime\n",
        "\n",
        "# Define the list to store programming languages for users who joined after 2020\n",
        "languages_after_2020 = []\n",
        "\n",
        "# Read the users CSV file to get the creation dates\n",
        "with open('users.csv', 'r', encoding='utf-8') as users_file:\n",
        "    users_reader = csv.DictReader(users_file)\n",
        "    users_after_2020 = []\n",
        "\n",
        "    for user in users_reader:\n",
        "        # Check if the user joined after 2020\n",
        "        created_at = datetime.strptime(user['created_at'], '%Y-%m-%dT%H:%M:%SZ')\n",
        "        if created_at.year > 2020:\n",
        "            users_after_2020.append(user['login'])\n",
        "\n",
        "# Read the repositories CSV file to count languages for these users\n",
        "with open('repositories.csv', 'r', encoding='utf-8') as repos_file:\n",
        "    repos_reader = csv.DictReader(repos_file)\n",
        "\n",
        "    for row in repos_reader:\n",
        "        if row['login'] in users_after_2020:\n",
        "            language = row.get('language', '').strip()\n",
        "            if language:  # Only consider non-empty language names\n",
        "                languages_after_2020.append(language)\n",
        "\n",
        "# Count the occurrence of each language\n",
        "language_counts = Counter(languages_after_2020)\n",
        "\n",
        "# Find the two most common languages\n",
        "most_common_languages = language_counts.most_common(2)\n",
        "\n",
        "# Print the second most common language if it exists\n",
        "if len(most_common_languages) > 1:\n",
        "    print(most_common_languages[1][0])  # Second most popular programming language\n",
        "else:\n",
        "    print(\"Less than two languages found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1caj_hsm8iE9",
        "outputId": "82bfee5a-a25f-44c0-8523-a30a9c2ee463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shell\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from collections import defaultdict\n",
        "\n",
        "# Dictionary to store total stars and counts for each language\n",
        "language_stars = defaultdict(lambda: {'total_stars': 0, 'repo_count': 0})\n",
        "\n",
        "# Read the repositories CSV file\n",
        "with open('repositories.csv', 'r', encoding='utf-8') as repos_file:\n",
        "    repos_reader = csv.DictReader(repos_file)\n",
        "\n",
        "    for row in repos_reader:\n",
        "        language = row.get('language', '').strip()\n",
        "        stars = int(row.get('stargazers_count', 0))\n",
        "\n",
        "        if language:  # Only consider non-empty language names\n",
        "            language_stars[language]['total_stars'] += stars\n",
        "            language_stars[language]['repo_count'] += 1\n",
        "\n",
        "# Calculate average stars for each language\n",
        "language_averages = {}\n",
        "\n",
        "for language, data in language_stars.items():\n",
        "    if data['repo_count'] > 0:  # Avoid division by zero\n",
        "        average_stars = data['total_stars'] / data['repo_count']\n",
        "        language_averages[language] = average_stars\n",
        "\n",
        "# Find the language with the highest average stars\n",
        "if language_averages:\n",
        "    highest_average_language = max(language_averages, key=language_averages.get)\n",
        "    highest_average_value = language_averages[highest_average_language]\n",
        "\n",
        "    print(f\"The language with the highest average number of stars per repository is '{highest_average_language}' with an average of {highest_average_value:.2f} stars.\")\n",
        "else:\n",
        "    print(\"No repositories found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ohi2ZGit8w73",
        "outputId": "c106d914-6b01-4b4f-8e18-20d24223d075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The language with the highest average number of stars per repository is 'Mermaid' with an average of 505.00 stars.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# List to store users and their leader strength\n",
        "leader_strengths = []\n",
        "\n",
        "# Read the users CSV file\n",
        "with open('users.csv', 'r', encoding='utf-8') as users_file:\n",
        "    reader = csv.DictReader(users_file)\n",
        "\n",
        "    for row in reader:\n",
        "        login = row['login']\n",
        "        followers = int(row['followers'])\n",
        "        following = int(row['following'])\n",
        "\n",
        "        # Calculate leader strength\n",
        "        leader_strength = followers / (1 + following) if following >= 0 else followers\n",
        "\n",
        "        leader_strengths.append({'login': login, 'leader_strength': leader_strength})\n",
        "\n",
        "# Sort users by leader strength in descending order\n",
        "sorted_users = sorted(leader_strengths, key=lambda x: x['leader_strength'], reverse=True)\n",
        "\n",
        "# Get the top 5 users\n",
        "top_5_users = sorted_users[:5]\n",
        "\n",
        "# Extract logins for the output\n",
        "top_5_logins = [user['login'] for user in top_5_users]\n",
        "\n",
        "# Print the result as a comma-separated list\n",
        "print(','.join(top_5_logins))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLqCGT4T9GYg",
        "outputId": "5f68de50-96cf-4592-cd60-82a941426286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "brendangregg,cornflourblue,Canva,nicknochnack,0vm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "# Lists to store followers and public repositories\n",
        "followers = []\n",
        "public_repos = []\n",
        "\n",
        "# Read the users CSV file\n",
        "with open('users.csv', 'r', encoding='utf-8') as users_file:\n",
        "    reader = csv.DictReader(users_file)\n",
        "\n",
        "    for row in reader:\n",
        "        followers.append(int(row['followers']))\n",
        "        public_repos.append(int(row['public_repos']))\n",
        "\n",
        "# Create a DataFrame to analyze the data\n",
        "data = pd.DataFrame({\n",
        "    'followers': followers,\n",
        "    'public_repos': public_repos\n",
        "})\n",
        "\n",
        "# Calculate the correlation\n",
        "correlation = data['followers'].corr(data['public_repos'])\n",
        "\n",
        "# Print the result\n",
        "print(f\"Correlation between number of followers and number of public repositories: {correlation:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4G7LY6f9aI3",
        "outputId": "bb36ab66-0f00-467d-80ae-1983cbc2fba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation between number of followers and number of public repositories: 0.0354\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Lists to store followers and public repositories\n",
        "followers = []\n",
        "public_repos = []\n",
        "\n",
        "# Read the users CSV file\n",
        "with open('users.csv', 'r', encoding='utf-8') as users_file:\n",
        "    reader = csv.DictReader(users_file)\n",
        "\n",
        "    for row in reader:\n",
        "        followers.append(int(row['followers']))\n",
        "        public_repos.append(int(row['public_repos']))\n",
        "\n",
        "# Create a DataFrame to analyze the data\n",
        "data = pd.DataFrame({\n",
        "    'followers': followers,\n",
        "    'public_repos': public_repos\n",
        "})\n",
        "\n",
        "# Define the independent variable (X) and dependent variable (y)\n",
        "X = data['public_repos']\n",
        "y = data['followers']\n",
        "\n",
        "# Add a constant to the independent variable\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit the regression model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Print the regression results\n",
        "print(model.summary())\n",
        "\n",
        "# Extract the coefficient for public_repos\n",
        "slope = model.params['public_repos']\n",
        "print(f\"Estimated additional followers per additional public repository: {slope:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Enr3Frd9sKg",
        "outputId": "3994f0a7-3d00-475a-dde5-3e73a406d396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:              followers   R-squared:                       0.001\n",
            "Model:                            OLS   Adj. R-squared:                 -0.001\n",
            "Method:                 Least Squares   F-statistic:                    0.4673\n",
            "Date:                Thu, 31 Oct 2024   Prob (F-statistic):              0.495\n",
            "Time:                        14:26:43   Log-Likelihood:                -3124.5\n",
            "No. Observations:                 375   AIC:                             6253.\n",
            "Df Residuals:                     373   BIC:                             6261.\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "================================================================================\n",
            "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
            "--------------------------------------------------------------------------------\n",
            "const          433.3140     53.543      8.093      0.000     328.031     538.598\n",
            "public_repos     0.0683      0.100      0.684      0.495      -0.128       0.265\n",
            "==============================================================================\n",
            "Omnibus:                      524.032   Durbin-Watson:                   0.061\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            59518.818\n",
            "Skew:                           7.094   Prob(JB):                         0.00\n",
            "Kurtosis:                      63.066   Cond. No.                         551.\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "Estimated additional followers per additional public repository: 0.0683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the repositories CSV file\n",
        "repositories = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Convert 'has_projects' and 'has_wiki' to integers (1 for True, 0 for False)\n",
        "repositories['has_projects'] = repositories['has_projects'].map({'true': 1, 'false': 0})\n",
        "repositories['has_wiki'] = repositories['has_wiki'].map({'true': 1, 'false': 0})\n",
        "\n",
        "# Calculate the correlation between has_projects and has_wiki\n",
        "correlation = repositories['has_projects'].corr(repositories['has_wiki'])\n",
        "\n",
        "# Print the correlation\n",
        "print(f\"Correlation between having projects enabled and having wiki enabled: {correlation:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAdsUvLt97Rj",
        "outputId": "a886eeaf-269b-497f-8ea6-6ed50b00b6b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation between having projects enabled and having wiki enabled: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the repositories CSV file\n",
        "repositories = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Check for missing values in 'has_projects' and 'has_wiki'\n",
        "print(\"Missing values before cleaning:\")\n",
        "print(repositories[['has_projects', 'has_wiki']].isnull().sum())\n",
        "\n",
        "# Clean up the has_projects and has_wiki columns\n",
        "# Map 'true'/'false' to 1/0, and fill NaNs with 0 (or you can drop them)\n",
        "repositories['has_projects'] = repositories['has_projects'].map({'true': 1, 'false': 0})\n",
        "repositories['has_wiki'] = repositories['has_wiki'].map({'true': 1, 'false': 0})\n",
        "\n",
        "# Fill NaN values with 0 (or you can choose to drop rows with NaN)\n",
        "repositories['has_projects'] = repositories['has_projects'].fillna(0)\n",
        "repositories['has_wiki'] = repositories['has_wiki'].fillna(0)\n",
        "\n",
        "# Check again for missing values after cleaning\n",
        "print(\"Missing values after cleaning:\")\n",
        "print(repositories[['has_projects', 'has_wiki']].isnull().sum())\n",
        "\n",
        "# Calculate the correlation between has_projects and has_wiki\n",
        "correlation = repositories['has_projects'].corr(repositories['has_wiki'])\n",
        "\n",
        "# Print the correlation\n",
        "print(f\"Correlation between having projects enabled and having wiki enabled: {correlation:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vcot7v86-LcU",
        "outputId": "05c7fbfe-1070-48ac-ddc2-3123899fd499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values before cleaning:\n",
            "has_projects    0\n",
            "has_wiki        0\n",
            "dtype: int64\n",
            "Missing values after cleaning:\n",
            "has_projects    0\n",
            "has_wiki        0\n",
            "dtype: int64\n",
            "Correlation between having projects enabled and having wiki enabled: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
            "  c /= stddev[:, None]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the users CSV file\n",
        "users = pd.read_csv('users.csv')\n",
        "\n",
        "# Clean up the hireable column\n",
        "# Convert 'true'/'false' to boolean and fill NaN with False\n",
        "users['hireable'] = users['hireable'].map({'true': True, 'false': False}).fillna(False)\n",
        "\n",
        "# Calculate average following count for hireable and non-hireable users\n",
        "average_following = users.groupby('hireable')['following'].mean()\n",
        "\n",
        "# Print the results\n",
        "print(\"Average number of users followed:\")\n",
        "print(f\"Hireable users: {average_following[True] if True in average_following.index else 'No hireable users'}\")\n",
        "print(f\"Non-hireable users: {average_following[False] if False in average_following.index else 'No non-hireable users'}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBwu48Kv-oWP",
        "outputId": "c83150b0-f76e-4200-e5bf-3e78e540229c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average number of users followed:\n",
            "Hireable users: No hireable users\n",
            "Non-hireable users: 103.096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-6c57028214ca>:8: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  users['hireable'] = users['hireable'].map({'true': True, 'false': False}).fillna(False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Load the users data from users.csv\n",
        "users = pd.read_csv('users.csv')\n",
        "\n",
        "# Filter out users without bios\n",
        "users = users[users['bio'].notna()]\n",
        "\n",
        "# Calculate the length of the bio in words\n",
        "users['bio_length'] = users['bio'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# Prepare the data for regression\n",
        "X = users['bio_length']  # Independent variable\n",
        "y = users['followers']  # Dependent variable\n",
        "\n",
        "# Add a constant to the independent variable\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit the regression model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Print the summary of the regression\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOMzvN0q_UCe",
        "outputId": "fbfeb78e-35ed-4774-a4e6-f276d0b05feb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:              followers   R-squared:                       0.003\n",
            "Model:                            OLS   Adj. R-squared:                 -0.001\n",
            "Method:                 Least Squares   F-statistic:                    0.8029\n",
            "Date:                Thu, 31 Oct 2024   Prob (F-statistic):              0.371\n",
            "Time:                        14:33:42   Log-Likelihood:                -2145.9\n",
            "No. Observations:                 253   AIC:                             4296.\n",
            "Df Residuals:                     251   BIC:                             4303.\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const        589.0681    131.159      4.491      0.000     330.756     847.381\n",
            "bio_length   -10.3042     11.499     -0.896      0.371     -32.952      12.343\n",
            "==============================================================================\n",
            "Omnibus:                      341.744   Durbin-Watson:                   0.087\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            23684.207\n",
            "Skew:                           6.299   Prob(JB):                         0.00\n",
            "Kurtosis:                      48.695   Cond. No.                         20.4\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from collections import Counter\n",
        "from datetime import datetime\n",
        "\n",
        "# Read the CSV file with UTF-8 encoding\n",
        "with open('repositories.csv', 'r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    weekend_users = []\n",
        "\n",
        "    for row in reader:\n",
        "        created_at = row['created_at']\n",
        "        if created_at:  # Ensure created_at is not empty\n",
        "            # Parse the created_at date\n",
        "            created_date = datetime.strptime(created_at, '%Y-%m-%dT%H:%M:%SZ')\n",
        "            # Check if the date is a weekend (Saturday=5, Sunday=6)\n",
        "            if created_date.weekday() in [5, 6]:\n",
        "                weekend_users.append(row['login'])\n",
        "\n",
        "# Count occurrences of each user\n",
        "weekend_user_counts = Counter(weekend_users)\n",
        "\n",
        "# Get the top 5 users who created the most repositories on weekends\n",
        "top_5_weekend_users = weekend_user_counts.most_common(5)\n",
        "\n",
        "# Extract the logins\n",
        "top_5_logins = [user[0] for user in top_5_weekend_users]\n",
        "\n",
        "# Print the result as a comma-separated list\n",
        "print(', '.join(top_5_logins))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gj73VtRu_5M1",
        "outputId": "449ddc75-8fca-4e0b-ba46-7655f33815d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "timgates42, pinkforest, johndpope, mvandermeulen, mikeyhodl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from collections import Counter\n",
        "\n",
        "# Define the list to store surnames\n",
        "surnames = []\n",
        "\n",
        "# Read the CSV file with UTF-8 encoding\n",
        "with open('users.csv', 'r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    for row in reader:\n",
        "        name = row['name']\n",
        "        if name:  # Ensure the name is not empty\n",
        "            # Split the name by whitespace and take the last word as the surname\n",
        "            surname = name.strip().split()[-1]\n",
        "            surnames.append(surname)\n",
        "\n",
        "# Count the occurrences of each surname\n",
        "surname_counts = Counter(surnames)\n",
        "\n",
        "# Find the most common surname(s)\n",
        "most_common_surnames = surname_counts.most_common()\n",
        "max_count = most_common_surnames[0][1]  # Get the count of the most common surname\n",
        "common_surnames = [surname for surname, count in most_common_surnames if count == max_count]\n",
        "\n",
        "# Sort the surnames alphabetically\n",
        "common_surnames.sort()\n",
        "\n",
        "# Print the result as a comma-separated list\n",
        "print(', '.join(common_surnames))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv002YZIALO4",
        "outputId": "746c6ba5-003e-4128-b36e-2a53b8267da5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wu, Zhang\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from collections import Counter\n",
        "from datetime import datetime\n",
        "\n",
        "# Define lists to store users and programming languages\n",
        "filtered_users = []\n",
        "languages = []\n",
        "\n",
        "# Read the users.csv file to filter users who joined after 2020\n",
        "with open('users.csv', 'r', encoding='utf-8') as user_file:\n",
        "    user_reader = csv.DictReader(user_file)\n",
        "    for row in user_reader:\n",
        "        created_at = row['created_at']\n",
        "        if created_at:  # Ensure the created_at is not empty\n",
        "            created_date = datetime.strptime(created_at, '%Y-%m-%dT%H:%M:%SZ')\n",
        "            if created_date.year > 2020:  # Check if user joined after 2020\n",
        "                filtered_users.append(row['login'])  # Store the login of the user\n",
        "\n",
        "# Read the repositories.csv file to count programming languages for the filtered users\n",
        "with open('repositories.csv', 'r', encoding='utf-8') as repo_file:\n",
        "    repo_reader = csv.DictReader(repo_file)\n",
        "    for row in repo_reader:\n",
        "        if row['login'] in filtered_users:  # Check if the repository belongs to the filtered users\n",
        "            language = row.get('language', '').strip()\n",
        "            if language:  # Ensure the language is not empty\n",
        "                languages.append(language)\n",
        "\n",
        "# Count the occurrences of each language\n",
        "language_counts = Counter(languages)\n",
        "\n",
        "# Find the second most common language\n",
        "if len(language_counts) >= 2:\n",
        "    # Sort the languages by count\n",
        "    second_most_common_language = language_counts.most_common(2)[1][0]\n",
        "else:\n",
        "    second_most_common_language = \"Not enough data\"\n",
        "\n",
        "# Print the result\n",
        "print(second_most_common_language)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QV0s748YAflC",
        "outputId": "ff8c5213-d9b0-424f-e0f2-522cfda1525a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shell\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from collections import Counter\n",
        "from datetime import datetime\n",
        "\n",
        "# Define lists to store programming languages and filtered users\n",
        "languages = []\n",
        "filtered_users = []\n",
        "\n",
        "# Read the users.csv file to filter users from Sydney who joined after 2020\n",
        "with open('users.csv', 'r', encoding='utf-8') as user_file:\n",
        "    user_reader = csv.DictReader(user_file)\n",
        "\n",
        "    for row in user_reader:\n",
        "        # Check if the user is from Sydney\n",
        "        location = row.get('location', '').strip().lower()\n",
        "        created_at = row.get('created_at', '').strip()\n",
        "\n",
        "        # Convert the date string to a datetime object\n",
        "        if created_at and 'sydney' in location:\n",
        "            user_join_date = datetime.strptime(created_at, \"%Y-%m-%dT%H:%M:%SZ\")\n",
        "\n",
        "            # Check if the user joined after 2020\n",
        "            if user_join_date.year > 2020:\n",
        "                # Store the user's login for later use\n",
        "                filtered_users.append(row['login'])\n",
        "\n",
        "# Read the repositories.csv file to count programming languages for the filtered users\n",
        "with open('repositories.csv', 'r', encoding='utf-8') as repo_file:\n",
        "    repo_reader = csv.DictReader(repo_file)\n",
        "\n",
        "    for row in repo_reader:\n",
        "        # Check if the repository belongs to the filtered users\n",
        "        if row['login'] in filtered_users:\n",
        "            # Get the language field and clean it up\n",
        "            language = row.get('language', '').strip()\n",
        "            if language:\n",
        "                languages.append(language)\n",
        "\n",
        "# Count the occurrence of each language\n",
        "language_counts = Counter(languages)\n",
        "\n",
        "# Find the two most common languages\n",
        "most_common_languages = language_counts.most_common(2)\n",
        "\n",
        "# Print the second most common language\n",
        "if len(most_common_languages) >= 2:\n",
        "    print(most_common_languages[1][0])  # Second most common language\n",
        "else:\n",
        "    print(\"Not enough language data found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kz9tfAnXAxw2",
        "outputId": "c8bc6a0d-9433-46a2-a113-9e7b429a0c15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shell\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Define lists to store bio lengths and followers\n",
        "bio_lengths = []\n",
        "followers_counts = []\n",
        "\n",
        "# Read the users.csv file with UTF-8 encoding\n",
        "with open('users.csv', 'r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "\n",
        "    for row in reader:\n",
        "        bio = row.get('bio', '').strip()\n",
        "        followers = int(row.get('followers', 0))\n",
        "\n",
        "        # Ignore users without a bio\n",
        "        if bio:\n",
        "            # Calculate the length of the bio in words\n",
        "            bio_length = len(bio.split())\n",
        "            bio_lengths.append(bio_length)\n",
        "            followers_counts.append(followers)\n",
        "\n",
        "# Prepare the data for regression analysis\n",
        "X = np.array(bio_lengths)  # Independent variable\n",
        "y = np.array(followers_counts)  # Dependent variable\n",
        "\n",
        "# Add a constant to the independent variable (required for statsmodels)\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Perform OLS regression\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Print the regression results\n",
        "print(model.summary())\n",
        "\n",
        "# Print the coefficient for bio length\n",
        "print(f\"Coefficient for bio length: {model.params[1]}\")\n"
      ],
      "metadata": {
        "id": "KrSmlehVCdPt",
        "outputId": "79500d37-a04b-47d7-c6ee-023402ef236f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.003\n",
            "Model:                            OLS   Adj. R-squared:                 -0.001\n",
            "Method:                 Least Squares   F-statistic:                    0.8029\n",
            "Date:                Thu, 31 Oct 2024   Prob (F-statistic):              0.371\n",
            "Time:                        14:47:36   Log-Likelihood:                -2145.9\n",
            "No. Observations:                 253   AIC:                             4296.\n",
            "Df Residuals:                     251   BIC:                             4303.\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const        589.0681    131.159      4.491      0.000     330.756     847.381\n",
            "x1           -10.3042     11.499     -0.896      0.371     -32.952      12.343\n",
            "==============================================================================\n",
            "Omnibus:                      341.744   Durbin-Watson:                   0.087\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            23684.207\n",
            "Skew:                           6.299   Prob(JB):                         0.00\n",
            "Kurtosis:                      48.695   Cond. No.                         20.4\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "Coefficient for bio length: -10.304242322818142\n"
          ]
        }
      ]
    }
  ]
}